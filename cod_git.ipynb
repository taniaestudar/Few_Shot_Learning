{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWkcfHKVLwVPtDZCzrWyMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taniaestudar/Few_Shot_Learning/blob/main/cod_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TÓPICOS EM OTIMIZAÇÃO\n",
        "## PROBLEMA DE META LEARNING E FEW SHOT\n",
        " Grupo 2:\n",
        "\n",
        "EDINEY PEDROZO MATHIAS\n",
        "\n",
        "MARIANA MIRELA FERREIRA\n",
        "\n",
        "SARAH RODRIGUES PREZOTTO\n",
        "\n",
        "TÂNIA CRISTINA VALASKY\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1WpcqNgjgfK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importações**"
      ],
      "metadata": {
        "id": "ApsRbGIAg4Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Manipulação de Imagens\n",
        "from PIL import Image\n",
        "\n",
        "# Visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Scikit-Learn (Machine Learning Tradicional)\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import (GridSearchCV, StratifiedKFold, train_test_split)\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, confusion_matrix, classification_report)\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# TensorFlow / Keras (Deep Learning)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "cjrap4HKghQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Baixar dataset e configurar caminho**\n",
        "\n",
        "O dataset que será utilizado é o “[dataset perros, gatos y aves](https://www.kaggle.com/datasets/diegosanand/dataset-perros-gatos-y-aves)”, encontrado na plataforma Kaggle. Essa base de dados contém oito diretórios de imagens - com gatos, cachorros e aves - que são compostos por dez imagens cada."
      ],
      "metadata": {
        "id": "6HpV8nevidUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse dataset, é formarmado por:\n",
        "\n",
        "- 80 imagens divididas em 8 pastas (10 imagens cada):\n",
        "  - 3 pastas (s1, s4, s7) → 30 imagens de cachorros;\n",
        "  - 3 pastas (s2, s5, s8) → 30 imagens de gatos;\n",
        "  - 2 pastas (s3, s6) → 20 imagens de aves.\n"
      ],
      "metadata": {
        "id": "WAQiWM7GjY2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# BAIXAR DATASET E DEFINIR CAMINHO\n",
        "# ==============================\n",
        "path_base = kagglehub.dataset_download(\"diegosanand/dataset-perros-gatos-y-aves\")\n",
        "print(\"Dataset baixado em:\", path_base)\n",
        "\n",
        "# Descobrir a pasta principal\n",
        "if \"Perros_gatos_aves\" in os.listdir(path_base):\n",
        "    caminho_dataset = os.path.join(path_base, \"Perros_gatos_aves\")\n",
        "else:\n",
        "    caminho_dataset = path_base\n",
        "\n",
        "print(\"Caminho do dataset a ser usado:\", caminho_dataset)\n",
        "\n",
        "# ==============================\n",
        "# INSPEÇÃO DAS CLASSES\n",
        "# ==============================\n",
        "classes = [d for d in os.listdir(caminho_dataset) if os.path.isdir(os.path.join(caminho_dataset, d))]\n",
        "classes.sort()\n",
        "\n",
        "print(\"\\n=== INFORMAÇÕES DO DATASET ===\")\n",
        "print(f\"Total de classes: {len(classes)}\")\n",
        "for classe in classes:\n",
        "    pasta = os.path.join(caminho_dataset, classe)\n",
        "    n_imgs = len([f for f in os.listdir(pasta) if f.lower().endswith((\".jpg\",\".png\",\".jpeg\"))])\n",
        "    print(f\"Classe: {classe} | Quantidade de imagens: {n_imgs}\")\n",
        "\n",
        "# ==============================\n",
        "# CARREGAR TODAS AS IMAGENS\n",
        "# ==============================\n",
        "def carregar_todas_imagens(caminho_dataset, max_imagens=None):\n",
        "    imagens = []\n",
        "    count = 0\n",
        "\n",
        "    for classe in classes:\n",
        "        pasta_classe = os.path.join(caminho_dataset, classe)\n",
        "        arquivos = [f for f in os.listdir(pasta_classe) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "\n",
        "        for arquivo in arquivos:\n",
        "            caminho_img = os.path.join(pasta_classe, arquivo)\n",
        "            try:\n",
        "                img = Image.open(caminho_img).convert(\"RGB\")\n",
        "                img_array = np.array(img, dtype=np.float32) / 255.0\n",
        "                imagens.append(img_array)\n",
        "                count += 1\n",
        "\n",
        "                if max_imagens is not None and count >= max_imagens:\n",
        "                    return imagens\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\"Erro ao abrir:\", caminho_img, e)\n",
        "\n",
        "    return imagens\n",
        "\n",
        "# Exemplo: carregar todas as imagens\n",
        "imagens = carregar_todas_imagens(caminho_dataset, max_imagens=None)\n",
        "print(f\"\\nTotal de imagens carregadas: {len(imagens)}\")"
      ],
      "metadata": {
        "id": "RRs6C80niZGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# MOSTRAR IMAGENS ORIGINAIS\n",
        "# ==============================\n",
        "def mostrar_imagens_originais(caminho_dataset, samples_per_class=2):\n",
        "    classes = os.listdir(caminho_dataset)\n",
        "    plt.figure(figsize=(12, 4*len(classes)))\n",
        "\n",
        "    for i, classe in enumerate(classes):\n",
        "        pasta_classe = os.path.join(caminho_dataset, classe)\n",
        "        arquivos = os.listdir(pasta_classe)\n",
        "        exemplos = random.sample(arquivos, min(samples_per_class, len(arquivos)))\n",
        "\n",
        "        for j, arquivo in enumerate(exemplos):\n",
        "            caminho_img = os.path.join(pasta_classe, arquivo)\n",
        "            img = Image.open(caminho_img)\n",
        "\n",
        "            plt.subplot(len(classes), samples_per_class, i*samples_per_class + j + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"{classe}\\n{img.size} | {img.mode}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Imagens Originais\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "mostrar_imagens_originais(caminho_dataset)"
      ],
      "metadata": {
        "id": "zwW0MSZ7jmBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EDA: Exploração e Preparação das Imagens**\n",
        "\n",
        "A EDA (Análise Exploratória de Dados) em imagens serve para entender como os dados estão distribuídos, se existe algum padrão ou problema, e como preparar corretamente o dataset para o modelo."
      ],
      "metadata": {
        "id": "5CcomEjQkYC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estatísticas globais das imagens originais**"
      ],
      "metadata": {
        "id": "tbxIeGyJkmNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CALCULAR MÉDIA E DESVIO-PADRÃO GLOBAL\n",
        "# ==============================\n",
        "all_pixels = np.concatenate([img.reshape(-1, 3) for img in imagens], axis=0)\n",
        "\n",
        "mean_global = np.mean(all_pixels, axis=0)\n",
        "std_global = np.std(all_pixels, axis=0)\n",
        "\n",
        "print(\"\\n=== ESTATÍSTICAS GLOBAIS ===\")\n",
        "print(\"Média global por canal (R,G,B):\", mean_global)\n",
        "print(\"Desvio-padrão global por canal (R,G,B):\", std_global)\n",
        "\n",
        "# ==============================\n",
        "# PLOTAR HISTOGRAMA GLOBAL\n",
        "# ==============================\n",
        "r = all_pixels[:,0]\n",
        "g = all_pixels[:,1]\n",
        "b = all_pixels[:,2]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(r, bins=256, color='red', alpha=0.5, label='R')\n",
        "plt.hist(g, bins=256, color='green', alpha=0.5, label='G')\n",
        "plt.hist(b, bins=256, color='blue', alpha=0.5, label='B')\n",
        "plt.title(f\"Histograma Global RGB — Total de pixels: {all_pixels.shape[0]}\")\n",
        "plt.xlabel(\"Intensidade (0-1)\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uBZnpFiNjt7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ajustando as imagens (dimensão + RGB + normalização)**\n",
        "\n",
        "Isso garante que todas as imagens tenham mesmo tamanho e a normalização melhora a estabilidade do treino."
      ],
      "metadata": {
        "id": "-m38EYsUlhER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# AJUSTANDO AS IMAGENS (RGB + 224x224)\n",
        "# ==============================\n",
        "def carregar_dataset(caminho_base, tamanho=(128,128)):\n",
        "    imagens, labels, classes = [], [], []\n",
        "    pastas = sorted(os.listdir(caminho_base))\n",
        "\n",
        "    for label, pasta in enumerate(pastas):\n",
        "        caminho_pasta = os.path.join(caminho_base, pasta)\n",
        "        arquivos = [f for f in os.listdir(caminho_pasta) if f.lower().endswith((\".jpg\"))]\n",
        "\n",
        "        classes.append(pasta)\n",
        "\n",
        "        for arquivo in arquivos:\n",
        "            caminho_img = os.path.join(caminho_pasta, arquivo)\n",
        "            try:\n",
        "                with Image.open(caminho_img) as img:\n",
        "                    if img.mode != \"RGB\":\n",
        "                        img = img.convert(\"RGB\")\n",
        "                    img = img.resize(tamanho)\n",
        "                    img_array = np.array(img, dtype=np.float32) / 255.0  # normalizado\n",
        "                    imagens.append(img_array)\n",
        "                    labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(\"Erro:\", caminho_img, e)\n",
        "\n",
        "    return np.array(imagens), np.array(labels), classes\n",
        "\n",
        "imagens, labels, classes = carregar_dataset(caminho_dataset)\n",
        "print(\"Shape das imagens:\", imagens.shape)\n",
        "print(\"Labels únicos:\", np.unique(labels))\n",
        "print(\"Classes:\", classes)"
      ],
      "metadata": {
        "id": "oWKhi2wxlakJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Estatísticas após ajuste**"
      ],
      "metadata": {
        "id": "FrevWfh5lw-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CALCULAR MÉDIA E DESVIO-PADRÃO GLOBAL APÓS AJUSTE\n",
        "# ==============================\n",
        "all_pixels = np.concatenate([img.reshape(-1, 3) for img in imagens], axis=0)\n",
        "\n",
        "mean_global = np.mean(all_pixels, axis=0)\n",
        "std_global = np.std(all_pixels, axis=0)\n",
        "\n",
        "print(\"\\n=== ESTATÍSTICAS GLOBAIS APÓS AJUSTE ===\")\n",
        "print(\"Média global por canal (R,G,B):\", mean_global)\n",
        "print(\"Desvio-padrão global por canal (R,G,B):\", std_global)\n",
        "\n",
        "# ==============================\n",
        "# PLOTAR HISTOGRAMA GLOBAL APÓS AJUSTE\n",
        "# ==============================\n",
        "r = all_pixels[:,0]\n",
        "g = all_pixels[:,1]\n",
        "b = all_pixels[:,2]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(r, bins=256, color='red', alpha=0.5, label='R')\n",
        "plt.hist(g, bins=256, color='green', alpha=0.5, label='G')\n",
        "plt.hist(b, bins=256, color='blue', alpha=0.5, label='B')\n",
        "plt.title(f\"Histograma Global RGB APÓS AJUSTE — Total de pixels: {all_pixels.shape[0]}\")\n",
        "plt.xlabel(\"Intensidade (0-1)\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KHQOwulQl1Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# MOSTRAR IMAGENS AJUSTADAS\n",
        "# ==============================\n",
        "def mostrar_imagens_ajustadas(X, y, classes, samples_per_class=3):\n",
        "    print(\"\\nMostrando imagens com o tamanho e formato ajustados:\")\n",
        "    num_classes = len(classes)\n",
        "    plt.figure(figsize=(12, 4 * num_classes))\n",
        "\n",
        "    for i, classe in enumerate(classes):\n",
        "        indices = np.where(y == i)[0]\n",
        "        exemplos = np.random.choice(indices, size=min(samples_per_class, len(indices)), replace=False)\n",
        "\n",
        "        for j, idx in enumerate(exemplos):\n",
        "            plt.subplot(num_classes, samples_per_class, i * samples_per_class + j + 1)\n",
        "            plt.imshow(X[idx])\n",
        "            plt.title(f\"{classe}\\nshape={X[idx].shape}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qD2IuLlLl6MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Criação de subconjuntos embaralhados**\n",
        "Nesta etapa, as imagens são embaralhadas e depois divididas em subconjuntos menores. Ou seja, cada subconjunto recebe uma mistura aleatória de cães, gatos e aves, isso impede que um subconjunto fique dominado por uma única classe."
      ],
      "metadata": {
        "id": "71xgyK5xnvTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# FUNÇÃO PARA CRIAR SUBCONJUNTOS EM MEMÓRIA\n",
        "# ==============================\n",
        "def criar_subconjuntos_memoria(imagens, labels, classes, num_subconjuntos=8, tam_subconjunto=10):\n",
        "    total_imgs = imagens.shape[0]\n",
        "    indices = list(range(total_imgs))\n",
        "    random.shuffle(indices)  # embaralhar todas as imagens\n",
        "\n",
        "    subconjuntos = []\n",
        "\n",
        "    for i in range(num_subconjuntos):\n",
        "        start = i * tam_subconjunto\n",
        "        end = start + tam_subconjunto\n",
        "        if end > total_imgs:  # caso não tenha imagens suficientes\n",
        "            end = total_imgs\n",
        "        subset_idx = indices[start:end]\n",
        "        subconjuntos.append((imagens[subset_idx], labels[subset_idx]))\n",
        "\n",
        "    return subconjuntos\n",
        "\n",
        "# ==============================\n",
        "# FUNÇÃO PARA PLOTAR SUBCONJUNTO\n",
        "# ==============================\n",
        "def plot_subconjunto_memoria(imagens_sub, labels_sub, classes, max_cols=5):\n",
        "    n = imagens_sub.shape[0]\n",
        "    cols = min(max_cols, n)\n",
        "    rows = (n + cols - 1) // cols\n",
        "\n",
        "    plt.figure(figsize=(15, rows * 3))\n",
        "    for i in range(n):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(imagens_sub[i])\n",
        "        plt.title(classes[labels_sub[i]], fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ==============================\n",
        "# CRIAR SUBCONJUNTOS\n",
        "# ==============================\n",
        "subconjuntos = criar_subconjuntos_memoria(imagens, labels, classes)\n",
        "\n",
        "# ==============================\n",
        "# PLOTAR TODOS OS SUBCONJUNTOS\n",
        "# ==============================\n",
        "for i, (imgs_sub, labels_sub) in enumerate(subconjuntos):\n",
        "    print(f\"Subconjunto {i+1} - Total de imagens: {imgs_sub.shape[0]}\")\n",
        "    plot_subconjunto_memoria(imgs_sub, labels_sub, classes)"
      ],
      "metadata": {
        "id": "aUyK7jspoFoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Divisão treino / validação / teste (70% / 15% / 15%)**\n",
        "\n",
        "Após os subconjuntos, as imagens são divididas em três partes essenciais:\n",
        "\n",
        "*   **Treino:** usado para ajustar os pesos do modelo;\n",
        "*   **Validação:** usado para ajustar hiperparâmetros;\n",
        "*   **Teste:** usado apenas para medir desempenho final."
      ],
      "metadata": {
        "id": "p7bZW7NmoUWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# DIVIDIR EM TREINO/VALIDAÇÃO/TESTE\n",
        "# ==============================\n",
        "# 70% treino, 15% validação, 15% teste\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(imagens, labels, test_size=0.3, stratify=labels, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(\"\\nTamanhos dos conjuntos:\")\n",
        "print(\"Treino:\", X_train.shape, \" Validação:\", X_val.shape, \" Teste:\", X_test.shape)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# MOSTRAR IMAGENS AJUSTADAS\n",
        "# ==============================\n",
        "def mostrar_imagens_ajustadas(X_train, y_train, classes, samples_per_class=3):\n",
        "\n",
        "    print(\"\\nMostrando imagens com o tamanho e formato ajustados:\")\n",
        "    num_classes = len(classes)\n",
        "    plt.figure(figsize=(12, 4*num_classes))\n",
        "\n",
        "    for i, classe in enumerate(classes):\n",
        "        indices = np.where(y_train == i)[0]\n",
        "        exemplos = np.random.choice(indices, size=min(samples_per_class, len(indices)), replace=False)\n",
        "\n",
        "        for j, idx in enumerate(exemplos):\n",
        "            plt.subplot(num_classes, samples_per_class, i*samples_per_class + j + 1)\n",
        "            plt.imshow(X_train[idx])\n",
        "            plt.title(f\"{classe}\\nshape={X_train[idx].shape}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "mostrar_imagens_ajustadas(X_train, y_train, classes)"
      ],
      "metadata": {
        "id": "m-qQVaa6oKK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Resultados Preliminares**"
      ],
      "metadata": {
        "id": "P-WdTBxho1rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Configuração Inicial**  \n",
        "Fixamos seeds para garantir reprodutibilidade dos resultados.\n"
      ],
      "metadata": {
        "id": "Co3TEvdjrgms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "7Qcm698spCyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Construção da CNN Base**  \n",
        "Conforme descrito no artigo (Moresco, 2022):\n",
        "\n",
        "- Modelo usado: **VGG16 pré-treinada no ImageNet**;\n",
        "- Todas as camadas convolucionais são **congeladas** (*transfer learning*);\n",
        "- A saída é compactada por **GlobalAveragePooling2D**;\n",
        "- Última camada é uma **densa de 128 neurônios**, produzindo o *embedding* usado pela SNN\n"
      ],
      "metadata": {
        "id": "saGcibyqrupp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def criar_cnn_base(input_shape=(128, 128, 3), embedding_dim=128):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Congelar camadas convolucionais\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(embedding_dim, activation='relu')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "1xxwwzW1r9-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Construção da Rede Neural Siamesa (SNN)**\n",
        "A SNN recebe duas imagens:\n",
        "\n",
        "- Extrai *embeddings* das duas imagens  \n",
        "- Calcula distância absoluta (L1)  \n",
        "- Passa por uma camada sigmoid para obter similaridade ∈ [0, 1]  \n",
        "\n",
        "Essa arquitetura é usada para verificar se duas imagens são da mesma classe.\n"
      ],
      "metadata": {
        "id": "bjbUEerXsKYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# MODELO SIAMESE\n",
        "# ==============================\n",
        "def criar_modelo_siamese(input_shape=(128, 128, 3)):\n",
        "    base_cnn = keras.Sequential([\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\")\n",
        "    ])\n",
        "\n",
        "    input_a = keras.Input(shape=input_shape)\n",
        "    input_b = keras.Input(shape=input_shape)\n",
        "\n",
        "    encoded_a = base_cnn(input_a)\n",
        "    encoded_b = base_cnn(input_b)\n",
        "\n",
        "    distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([encoded_a, encoded_b])\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "\n",
        "    model = keras.Model(inputs=[input_a, input_b], outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "yyu812wxsHdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Gerador de Batches (Algoritmo 1)**\n",
        "\n",
        "Cada batch contém:\n",
        "- 50% pares **positivos** (mesma classe → label = 1)  \n",
        "- 50% pares **negativos** (classes diferentes → label = 0)\n"
      ],
      "metadata": {
        "id": "VFQtD-MeuDos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_batch(X, y, batch_size=64):\n",
        "    metade = batch_size // 2\n",
        "    X1, X2, labels = [], [], []\n",
        "    classes = np.unique(y)\n",
        "\n",
        "    for _ in range(metade):\n",
        "        cls = random.choice(classes)\n",
        "        idx = np.where(y == cls)[0]\n",
        "\n",
        "        if len(idx) < 2:\n",
        "            i1, i2 = np.random.choice(idx, 2, replace=True)\n",
        "        else:\n",
        "            i1, i2 = np.random.choice(idx, 2, replace=False)\n",
        "\n",
        "        X1.append(X[i1])\n",
        "        X2.append(X[i2])\n",
        "        labels.append(1)\n",
        "\n",
        "        cls1, cls2 = np.random.choice(classes, 2, replace=False)\n",
        "        i1 = np.random.choice(np.where(y == cls1)[0])\n",
        "        i2 = np.random.choice(np.where(y == cls2)[0])\n",
        "        X1.append(X[i1])\n",
        "        X2.append(X[i2])\n",
        "        labels.append(0)\n",
        "\n",
        "    return np.array(X1), np.array(X2), np.array(labels)"
      ],
      "metadata": {
        "id": "SOlyLwy7uApu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Treinamento do Modelo Siames**\n",
        "Treinamento manual époco-a-época usando `train_on_batch`.  \n",
        "Mostramos o progresso a cada 10 épocas.\n"
      ],
      "metadata": {
        "id": "iaq9KBPIuTC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CRIAR E COMPILAR MODELO\n",
        "# ==============================\n",
        "snn = criar_modelo_siamese()\n",
        "snn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TJwg9wOHuYkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    X1_batch, X2_batch, y_batch = gerar_batch(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "    loss, acc = snn.train_on_batch([X1_batch, X2_batch], y_batch)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Época {epoch}/{EPOCHS} - Loss: {loss:.4f} - Acurácia: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "oYWtUW1QulxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loss vs Acurácia**\n",
        "\n",
        "  - ***Loss*** mede quão perto a previsão está do rótulo verdadeiro. Então quanto menor o valor do loss, melhor é o resultado;\n",
        "  - ***Acurácia*** mede quantos pares foram classificados corretamente.\n",
        "\n",
        "Para interpretarmos os resultados da célula anterior, podemos observar que, a partir da época 10, o modelo já começa a aprender padrões, pois a loss diminui e a acurácia melhora em relação à época 0. No início (época 0), o modelo estava praticamente aleatório, com uma loss muito alta. Já na época 30, ele começou a capturar o conceito de similaridade entre imagens, e na época 40 mostrou progresso contínuo. Cada vez que a loss diminui e a acurácia aumenta, isso indica que o modelo está aprendendo melhor a diferenciar as classes."
      ],
      "metadata": {
        "id": "m-v69Untuqvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Predição de similaridade**"
      ],
      "metadata": {
        "id": "fw-4F4Z2vPx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Função de Análise por Classe mostra:\n",
        "\n",
        "1. Imagens da classe no treino  \n",
        "2. Define uma imagem de referência no teste  \n",
        "3. Compara com todas as imagens do teste  \n",
        "4. Ordena por similaridade  \n",
        "5. Mostra visualização lado a lado  \n"
      ],
      "metadata": {
        "id": "E5r-S2hCve3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classes disponíveis no dataset:\")\n",
        "print(classes)\n",
        "\n",
        "def analisar_classe(classe_desejada, X_train, y_train, X_test, y_test, classes, modelo_siamese, max_imgs=20, imagens_por_tela=10, limiar=0.5):\n",
        "    \"\"\"\n",
        "    Analisa uma classe específica:\n",
        "    1. Mostra imagens dessa classe no conjunto de treino\n",
        "    2. Usa uma imagem do conjunto de teste como referência\n",
        "    3. Prediz similaridade com todas as imagens do teste\n",
        "    4. Mostra os resultados organizados\n",
        "    \"\"\"\n",
        "\n",
        "    # ==============================\n",
        "    # 1. Mostrar imagens da classe no treino\n",
        "    # ==============================\n",
        "    indice_classe = classes.index(classe_desejada)\n",
        "    indices = np.where(y_train == indice_classe)[0]\n",
        "    imgs_classe = X_train[indices]\n",
        "    total_imgs = len(imgs_classe)\n",
        "\n",
        "    print(f\"Total de imagens da classe '{classe_desejada}' no treino: {total_imgs}\")\n",
        "\n",
        "    max_imgs = min(total_imgs, max_imgs)\n",
        "    plt.figure(figsize=(15, 3 * (max_imgs // 5 + 1)))\n",
        "    for i in range(max_imgs):\n",
        "        plt.subplot((max_imgs // 5) + 1, 5, i + 1)\n",
        "        plt.imshow(imgs_classe[i])\n",
        "        plt.title(f\"{classe_desejada} - {i+1}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ==============================\n",
        "    # 2. Escolher uma imagem de referência no teste\n",
        "    # ==============================\n",
        "    idx_ref = np.where(y_test == indice_classe)[0][0]\n",
        "    img_ref = X_test[idx_ref]\n",
        "\n",
        "    # ==============================\n",
        "    # 3. Predizer similaridade com todas as imagens do teste\n",
        "    # ==============================\n",
        "    similaridades = []\n",
        "    for i in range(len(X_test)):\n",
        "        pred = modelo_siamese.predict([img_ref[np.newaxis, ...], X_test[i][np.newaxis, ...]])[0][0]\n",
        "        similaridades.append(pred)\n",
        "    similaridades = np.array(similaridades)\n",
        "\n",
        "    # ==============================\n",
        "    # 4. Ordenar e mostrar resultados\n",
        "    # ==============================\n",
        "    indices_ordenados = np.argsort(similaridades)[::-1]\n",
        "    num_telas = int(np.ceil(len(X_test) / imagens_por_tela))\n",
        "\n",
        "    for t in range(num_telas):\n",
        "        start = t * imagens_por_tela\n",
        "        end = min(start + imagens_por_tela, len(X_test))\n",
        "        subset_idx = indices_ordenados[start:end]\n",
        "\n",
        "        plt.figure(figsize=(12, 3 * len(subset_idx)))\n",
        "        for i, idx in enumerate(subset_idx):\n",
        "            img_cmp = X_test[idx]\n",
        "            pred = similaridades[idx]\n",
        "            resposta = f\"É {classe_desejada}\" if pred > limiar else f\"Não é {classe_desejada}\"\n",
        "\n",
        "            # Mostrar lado a lado\n",
        "            plt.subplot(len(subset_idx), 2, 2*i + 1)\n",
        "            plt.imshow(img_ref)\n",
        "            plt.title(f\"Imagem de Referência ({classe_desejada})\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.subplot(len(subset_idx), 2, 2*i + 2)\n",
        "            plt.imshow(img_cmp)\n",
        "            plt.title(f\"{resposta}\\nClasse real: {classes[y_test[idx]]} | Similaridade: {pred:.2f}\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "aycM_Ck3vmGM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rodando análise para todas as classes\n",
        "\n",
        "for c in classes:\n",
        "  print(f\"\\n=== Analisando a classe {c} ===\")\n",
        "  analisar_classe(c, X_train, y_train, X_test, y_test, classes, snn)"
      ],
      "metadata": {
        "id": "Rbl8k-E_vpYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Uma breve dos resultados obtidos até aqui**\n",
        "Uma observação importante é que, ao comparar a imagem de referência com ela mesma, seria esperado obter uma similaridade muito próxima de 1, já que se trata da mesma imagem. No entanto, o modelo retornou apenas **0,5**, o que indica que ele ainda não aprendeu a produzir embeddings suficientemente próximos para imagens idênticas. Nossa equipe identificou dois fatores principais que podem explicar esse comportamento:\n",
        "\n",
        "1. **Treinamento insuficiente:** o modelo foi atualizado apenas 50 vezes usando `train_on_batch`, o que é muito pouco para que aprenda a estruturar adequadamente o espaço de embeddings.\n",
        "2. **Dataset reduzido:** com poucas amostras por classe, a rede não consegue generalizar bem, o que prejudica a formação de representações discriminativas.\n",
        "\n",
        "Ao observar as demais predições, percebe-se que os valores de similaridade apresentam certa aleatoriedade. Por exemplo, um gato atingiu similaridade 0,79 em relação a um cachorro — um claro falso positivo, evidenciando que o modelo ainda não diferencia bem as classes. Isso é esperado em cenários com poucos dados e pouco treinamento, onde embeddings de classes distintas acabam ficando próximos.\n",
        "\n",
        "Além disso, tanto para a classe S1 quanto para as demais, a maioria das imagens recebe valores de similaridade muito baixos. O modelo acerta pouco e parece saturar sua saída (valores muito altos ou muito próximos de zero), sem apresentar uma transição clara entre classes semelhantes e distintas.\n",
        "\n",
        "Em síntese, o modelo ainda **não é confiável**. Não é necessário analisar todas as predições para perceber isso: o simples fato de uma imagem ser comparada com ela mesma e obter similaridade 0,5 já evidencia que a representação aprendida não está adequada.\n",
        "\n",
        "Para melhorar o desempenho nas próximas etapas, planejamos:\n",
        "\n",
        "* **Aumentar significativamente o tempo de treinamento**, gerando mais batches com exemplos positivos e negativos;\n",
        "* **Utilizar múltiplas imagens de referência por classe** e calcular a média das similaridades, reduzindo a variabilidade;\n",
        "* **Expandir o dataset**, quando possível, sem descaracterizar a proposta de meta-learning;\n",
        "* **Inspecionar os *embeddings* gerados**, avaliando se há separação entre classes.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zbG1HrfyzlVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Melhorando o Modelo**\n",
        "\n",
        "#### **Aumento de Épocas e Tamanho do Batch**\n",
        "\n",
        "Agora iniciamos a fase de aprimoramento do modelo, começando pelo aumento do número de épocas e do tamanho do batch.  \n",
        "Isso significa, na prática, oferecer mais tempo de treinamento ao modelo e fornecer mais exemplos positivos e negativos a cada batch, permitindo que a rede aprenda melhor o conceito de similaridade.\n",
        "\n",
        "Em vez de testar manualmente cada combinação, vamos definir listas de valores maiores que 50 épocas e maiores que 64 imagens por batch.  \n",
        "Para cada configuração, registraremos a *training loss* e a *training accuracy*, além de calcular o desempenho final médio no conjunto de validação.\n"
      ],
      "metadata": {
        "id": "XdcbeAmX1qz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_list = [60, 110, 160]\n",
        "batch_list = [128, 256, 512]\n",
        "\n",
        "VAL_N_BATCHES = 20\n",
        "\n",
        "def avaliar_em_batches(model, X, y, batch_size, n_batches=VAL_N_BATCHES):\n",
        "    losses, accs = [], []\n",
        "    for _ in range(n_batches):\n",
        "        X1b, X2b, yb = gerar_batch(X, y, batch_size=batch_size)\n",
        "        loss, acc = model.test_on_batch([X1b, X2b], yb)\n",
        "        losses.append(loss)\n",
        "        accs.append(acc)\n",
        "    return float(np.mean(losses)), float(np.mean(accs))\n",
        "\n",
        "results = {}\n",
        "\n",
        "for BATCH_SIZE in batch_list:\n",
        "    for EPOCHS in epoch_list:\n",
        "        run_name = f\"ep{EPOCHS}_bs{BATCH_SIZE}\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"Rodando: {run_name} — {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "        model = criar_modelo_siamese(input_shape=(128,128,3))\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        steps_per_epoch = max(1, len(X_train) // max(1, BATCH_SIZE))\n",
        "\n",
        "        hist = {'loss': [], 'acc': []}\n",
        "\n",
        "        for epoch in range(1, EPOCHS + 1):\n",
        "            epoch_loss, epoch_acc = 0.0, 0.0\n",
        "            for step in range(steps_per_epoch):\n",
        "                X1_batch, X2_batch, y_batch = gerar_batch(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "                loss, acc = model.train_on_batch([X1_batch, X2_batch], y_batch)\n",
        "                epoch_loss += loss\n",
        "                epoch_acc += acc\n",
        "            epoch_loss /= steps_per_epoch\n",
        "            epoch_acc /= steps_per_epoch\n",
        "\n",
        "            hist['loss'].append(epoch_loss)\n",
        "            hist['acc'].append(epoch_acc)\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == 1 or epoch == EPOCHS:\n",
        "                print(f\"Run {run_name} — Época {epoch}/{EPOCHS} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        val_loss, val_acc = avaliar_em_batches(model, X_val, y_val, batch_size=BATCH_SIZE, n_batches=VAL_N_BATCHES)\n",
        "        print(f\"Resultado final (val médio): Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
        "\n",
        "        results[run_name] = {\n",
        "            'EPOCHS': EPOCHS,\n",
        "            'BATCH_SIZE': BATCH_SIZE,\n",
        "            'history': hist,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "            'model': model #isso serve pra guardar o modelo, mas pode encher a memória\n",
        "        }"
      ],
      "metadata": {
        "id": "i3_upQNszt5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualizando o Histórico de Treinamento**\n",
        "\n",
        "Para cada combinação de épocas e batch size, vamos gerar gráficos de loss e acurácia, permitindo visualizar o comportamento do modelo ao longo das iterações.\n",
        "\n",
        "Isso ajuda a identificar tendências como:\n",
        "- convergência lenta ou rápida\n",
        "- overfitting\n",
        "- instabilidade do treinamento\n"
      ],
      "metadata": {
        "id": "_5Q7Gkk824Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for run_name, info in results.items():\n",
        "    hist = info['history']\n",
        "    epochs = len(hist['loss'])\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.suptitle(run_name)\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(range(1, epochs+1), hist['loss'])\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(range(1, epochs+1), hist['acc'])\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Acurácia')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IJLA65F623Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Salvando os Resultados Consolidado em um DataFrame**\n"
      ],
      "metadata": {
        "id": "fa05xjYz3zjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria uma lista com os resultados resumidos\n",
        "dados = []\n",
        "for run_name, info in results.items():\n",
        "    dados.append({\n",
        "        \"Execução\": run_name,\n",
        "        \"Épocas\": info[\"EPOCHS\"],\n",
        "        \"Batch_Size\": info[\"BATCH_SIZE\"],\n",
        "        \"Val_Loss\": info[\"val_loss\"],\n",
        "        \"Val_Acc\": info[\"val_acc\"]\n",
        "    })\n",
        "\n",
        "# Converte em DataFrame e salva\n",
        "df_resultados = pd.DataFrame(dados)\n",
        "df_resultados.to_csv(\"resultados_treinos.csv\", index=False)\n",
        "\n",
        "print(\"\\n Resultados salvos em 'resultados_treinos.csv'\")\n",
        "display(df_resultados)"
      ],
      "metadata": {
        "id": "gqx3b51i3pxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Avaliação Qualitativa dos Modelos**\n",
        "\n",
        "Agora, vamos examinar visualmente como cada modelo se comporta ao comparar uma imagem de referência com outras imagens do conjunto de teste.\n",
        "\n",
        "Isso permite observar:\n",
        "- se a similaridade está coerente;\n",
        "- se as classes estão mais separadas;\n",
        "- se há evolução em relação ao modelo inicial.\n"
      ],
      "metadata": {
        "id": "yilnbusw4_XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enumerar modelos de 1 a 9 conforme a ordem da execução\n",
        "modelos_numerados = {}\n",
        "\n",
        "for i, (run_name, info) in enumerate(results.items(), start=1):\n",
        "    nome_modelo = f\"modelo_{i}_{run_name}\"\n",
        "    modelos_numerados[nome_modelo] = info['model']\n",
        "    print(f\"{i}. {run_name} — Val_Loss={info['val_loss']:.4f} — Val_Acc={info['val_acc']:.4f}\")"
      ],
      "metadata": {
        "id": "hrzlEH0J5CFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comparar_modelos_por_classe(classe_desejada, X_train, y_train, X_test, y_test, classes, resultados, max_imgs=5, limiar=0.5):\n",
        "    \"\"\"\n",
        "    Compara visualmente os modelos treinados (armazenados em 'resultados')\n",
        "    para uma classe específica, mostrando lado a lado o desempenho.\n",
        "    \"\"\"\n",
        "    indice_classe = classes.index(classe_desejada)\n",
        "    idx_ref = np.where(y_test == indice_classe)[0][0]\n",
        "    img_ref = X_test[idx_ref]\n",
        "\n",
        "    print(f\"\\nComparando modelos para a classe: {classe_desejada}\")\n",
        "    print(f\"Imagem de referência — Classe real: {classe_desejada}\")\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(img_ref)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Inclui a imagem de referência e outras aleatórias\n",
        "    indices_aleatorios = np.concatenate(([idx_ref], np.random.choice(len(X_test), max_imgs - 1, replace=False)))\n",
        "\n",
        "    # Para cada modelo\n",
        "    for i, (run_name, info) in enumerate(resultados.items(), 1):\n",
        "        modelo = info[\"model\"]\n",
        "        preds = []\n",
        "\n",
        "        for idx in indices_aleatorios:\n",
        "            pred = modelo.predict([img_ref[np.newaxis, ...], X_test[idx][np.newaxis, ...]])[0][0]\n",
        "            preds.append((idx, pred))\n",
        "\n",
        "        print(f\"\\n=== Modelo {i} — {run_name} ===\")\n",
        "        plt.figure(figsize=(14, 3))\n",
        "        for j, (idx, pred) in enumerate(preds):\n",
        "            plt.subplot(1, max_imgs, j + 1)\n",
        "            plt.imshow(X_test[idx])\n",
        "            pred_classe = classes[y_test[idx]]\n",
        "            titulo = f\"{pred_classe}\\nSimilaridade: {pred:.2f} → {'É Similar' if pred > limiar else 'Não é'}\"\n",
        "            plt.title(titulo)\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "        plt.suptitle(f\"Modelo {i}: {run_name}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "dWYbru6b5G3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparação para todas as classes:\n",
        "\n",
        "for c in classes:\n",
        "    comparar_modelos_por_classe(c, X_train, y_train, X_test, y_test, classes, results)\n"
      ],
      "metadata": {
        "id": "-jB7_vbl5Od_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ajuste no código**\n",
        "\n",
        "Agora ajustamos a função de comparação entre modelos para garantir:\n",
        "\n",
        "- Normalização coerente das imagens antes da predição;\n",
        "\n",
        "- Impressão da auto-similaridade, que é o caso mais crítico;\n",
        "\n",
        "- Comparação mais limpa entre modelos, com média das outras similaridades.\n",
        "\n",
        "Isso nos permite identificar de forma clara que todos os modelos ainda falham em gerar similaridade ≈ 1 para a mesma imagem, o que já indica que a perda usada (*binary crossentropy*) não está orientando bem os *embeddings*."
      ],
      "metadata": {
        "id": "idgJDdDw5cgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comparar_modelos_por_classe(classe_desejada, X_train, y_train, X_test, y_test, classes, resultados, max_imgs=5, limiar=0.5):\n",
        "    \"\"\"\n",
        "    Compara visualmente os modelos treinados para uma classe específica,\n",
        "    mostrando lado a lado o desempenho de cada um.\n",
        "    Agora garante normalização correta e exibe a auto-similaridade da imagem.\n",
        "    \"\"\"\n",
        "    indice_classe = classes.index(classe_desejada)\n",
        "\n",
        "    # Selecionar imagem de referência\n",
        "    idx_ref = np.where(y_test == indice_classe)[0][0]\n",
        "    img_ref = X_test[idx_ref].astype(np.float32)\n",
        "\n",
        "    print(f\"\\nComparando modelos para a classe: {classe_desejada}\")\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(img_ref)\n",
        "    plt.title(f\"Imagem de referência — {classe_desejada}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Selecionar outras imagens aleatórias (de classes variadas)\n",
        "    indices_aleatorios = np.random.choice(len(X_test), max_imgs - 1, replace=False)\n",
        "    indices_aleatorios = np.concatenate(([idx_ref], indices_aleatorios))\n",
        "\n",
        "    for i, (run_name, info) in enumerate(resultados.items(), 1):\n",
        "        modelo = info[\"model\"]\n",
        "\n",
        "        print(f\"\\n=== Modelo {i} — {run_name} ===\")\n",
        "\n",
        "        preds = []\n",
        "        for idx in indices_aleatorios:\n",
        "            img_comp = X_test[idx].astype(np.float32)\n",
        "            pred = modelo.predict([img_ref[np.newaxis, ...], img_comp[np.newaxis, ...]], verbose=0)[0][0]\n",
        "            preds.append((idx, pred))\n",
        "\n",
        "        # Mostrar valor da auto-similaridade\n",
        "        pred_auto = preds[0][1]\n",
        "        print(f\"Similaridade da imagem consigo mesma: {pred_auto:.4f}\")\n",
        "        print(f\"Média de similaridade com outras imagens: {np.mean([p for _, p in preds[1:]]):.4f}\")\n",
        "\n",
        "        # Plotagem\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        for j, (idx, pred) in enumerate(preds):\n",
        "            plt.subplot(1, max_imgs, j + 1)\n",
        "            plt.imshow(X_test[idx])\n",
        "            pred_classe = classes[y_test[idx]]\n",
        "            titulo = f\"{pred_classe}\\nSimilaridade: {pred:.2f} → {'É similar' if pred > limiar else 'Não é'}\"\n",
        "            plt.title(titulo, fontsize=9)\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "        plt.suptitle(f\"Modelo {i}: {run_name}\", fontsize=12, y=1.05)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "dzDas4oD5fEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in classes:\n",
        "    comparar_modelos_por_classe(c, X_train, y_train, X_test, y_test, classes, results)"
      ],
      "metadata": {
        "id": "PXqBODpS5mf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Análise:**\n",
        "\n",
        "Mesmo após os ajustes realizados, a imagem de referência ainda não apresenta similaridade 1 consigo mesma. O modelo continua produzindo valores próximos de 0.5, mesmo quando comparamos duas imagens idênticas.\n",
        "\n",
        "Isso indica que a rede não está calibrando corretamente a saída da sigmoide.\n",
        "Esse comportamento é comum quando usamos *binary crossentropy* em modelos siameses baseados em *embeddings*: em vez de aprender distâncias reais, a rede tende a adotar uma saída \"neutra\".\n",
        "\n",
        "Uma alternativa mais apropriada para redes siamesas é a contrastive loss, pois ela estrutura diretamente o espaço de embeddings.\n",
        "Com ela, o modelo é incentivado a:\n",
        "\n",
        "- Aproximar embeddings quando as amostras pertencem à mesma classe;\n",
        "\n",
        "- Afastar embeddings quando as amostras são de classes diferentes."
      ],
      "metadata": {
        "id": "NrPIoagB7eRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------------------\n",
        "# 1. Função de perda contrastiva\n",
        "# -------------------------------------------------------------\n",
        "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
        "    \"\"\"\n",
        "    y_true: 1 = diferentes, 0 = iguais\n",
        "    y_pred: distância euclidiana entre embeddings\n",
        "    \"\"\"\n",
        "    squared_pred = K.square(y_pred)\n",
        "    margin_term = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean((1 - y_true) * squared_pred + y_true * margin_term)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2. Distância Euclidiana\n",
        "# -------------------------------------------------------------\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3. Modelo base (gera embeddings)\n",
        "# -------------------------------------------------------------\n",
        "def criar_modelo_base(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    embedding = layers.Dense(64)(x)\n",
        "    embedding = layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(embedding)\n",
        "\n",
        "    return models.Model(inputs, embedding)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 4. Rede Siamesa completa\n",
        "# -------------------------------------------------------------\n",
        "def criar_rede_siamese(input_shape):\n",
        "    base_model = criar_modelo_base(input_shape)\n",
        "    input_a = layers.Input(shape=input_shape)\n",
        "    input_b = layers.Input(shape=input_shape)\n",
        "\n",
        "    embedding_a = base_model(input_a)\n",
        "    embedding_b = base_model(input_b)\n",
        "\n",
        "    distancia = layers.Lambda(euclidean_distance)([embedding_a, embedding_b])\n",
        "    siamese_model = models.Model(inputs=[input_a, input_b], outputs=distancia)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    siamese_model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
        "    return siamese_model\n",
        "\n",
        "# ==============================\n",
        "# 5. GERAR PARES PARA O MODELO SIAMESE\n",
        "# ==============================\n",
        "def gerar_pares_hard(X, y, n_pairs_per_class=10):\n",
        "    \"\"\"\n",
        "    Gera pares (positivos e negativos) para treino de rede siamesa.\n",
        "    - 0 = pares da mesma classe\n",
        "    - 1 = pares de classes diferentes\n",
        "\n",
        "    Deixa robusto para o caso de alguma classe ter poucas amostras\n",
        "    (por exemplo, no conjunto de validação ou teste).\n",
        "    \"\"\"\n",
        "    pares_a, pares_b, labels = [], [], []\n",
        "\n",
        "    y = np.array(y)\n",
        "    classes = np.unique(y)\n",
        "    idx_por_classe = {c: np.where(y == c)[0] for c in classes}\n",
        "\n",
        "    # Só usa classes com pelo menos 2 amostras (para formar pares positivos)\n",
        "    classes_validas = [c for c in classes if len(idx_por_classe[c]) >= 2]\n",
        "\n",
        "    if len(classes_validas) == 0:\n",
        "        raise ValueError(\n",
        "            \"Nenhuma classe tem pelo menos 2 amostras para gerar pares positivos. \"\n",
        "            \"Verifique o conjunto passado para gerar_pares_hard.\"\n",
        "        )\n",
        "    if len(classes_validas) == 1:\n",
        "        raise ValueError(\n",
        "            \"Apenas uma classe tem pelo menos 2 amostras; \"\n",
        "            \"não é possível gerar pares negativos entre classes diferentes.\"\n",
        "        )\n",
        "\n",
        "    for c in classes_validas:\n",
        "        idx_c = idx_por_classe[c]\n",
        "\n",
        "        for _ in range(n_pairs_per_class):\n",
        "            # -------- Pares positivos (mesma classe) --------\n",
        "            i, j = np.random.choice(idx_c, 2, replace=False)\n",
        "            pares_a.append(X[i])\n",
        "            pares_b.append(X[j])\n",
        "            labels.append(0)  # 0 = iguais\n",
        "\n",
        "            # -------- Pares negativos (classes diferentes) --------\n",
        "            classes_negativas = [cn for cn in classes_validas if cn != c]\n",
        "            c_neg = np.random.choice(classes_negativas)\n",
        "            idx_c_neg = idx_por_classe[c_neg]\n",
        "\n",
        "            i = np.random.choice(idx_c)\n",
        "            j = np.random.choice(idx_c_neg)\n",
        "            pares_a.append(X[i])\n",
        "            pares_b.append(X[j])\n",
        "            labels.append(1)  # 1 = diferentes\n",
        "\n",
        "    return np.array(pares_a), np.array(pares_b), np.array(labels)\n",
        "\n",
        "# Gerar pares para treino, validação e teste\n",
        "pairs_train_a, pairs_train_b, y_train_pairs = gerar_pares_hard(X_train, y_train)\n",
        "pairs_val_a, pairs_val_b, y_val_pairs = gerar_pares_hard(X_val, y_val)\n",
        "pairs_test_a, pairs_test_b, y_test_pairs = gerar_pares_hard(X_test, y_test)\n",
        "\n",
        "print(\"Pares gerados:\")\n",
        "print(\"Treino:\", pairs_train_a.shape, pairs_train_b.shape)\n",
        "print(\"Validação:\", pairs_val_a.shape, pairs_val_b.shape)\n",
        "print(\"Teste:\", pairs_test_a.shape, pairs_test_b.shape)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 6. Função para converter distância → similaridade\n",
        "# -------------------------------------------------------------\n",
        "def prever_similaridade(model, img1, img2):\n",
        "    dist = model.predict([np.expand_dims(img1, 0), np.expand_dims(img2, 0)])\n",
        "    sim = np.exp(-dist)  # converte distância para similaridade (0 a 1)\n",
        "    return sim\n",
        "\n",
        "def comparar_modelos_por_classe(classe_desejada, X_test, y_test, classes, resultados,\n",
        "                                max_imgs=5, mostrar_exemplos=True):\n",
        "    \"\"\"\n",
        "    Compara visualmente os modelos treinados (armazenados em 'resultados')\n",
        "    para uma classe específica, mostrando a separação das distâncias entre pares\n",
        "    e exemplos visuais de comparação (iguais e diferentes).\n",
        "    \"\"\"\n",
        "    print(f\"\\nComparando modelos para a classe: {classe_desejada}\")\n",
        "\n",
        "    # Seleciona índices da classe e de outras classes\n",
        "    idx_classe = classes.index(classe_desejada)\n",
        "    idx_positivos = np.where(y_test == idx_classe)[0]\n",
        "    idx_negativos = np.where(y_test != idx_classe)[0]\n",
        "\n",
        "    if len(idx_positivos) < 2:\n",
        "        print(f\"Poucas imagens na classe {classe_desejada} para comparação.\")\n",
        "        return\n",
        "\n",
        "    # Seleciona subconjuntos de imagens\n",
        "    X_classe = X_test[np.random.choice(\n",
        "        idx_positivos, min(max_imgs, len(idx_positivos)), replace=False\n",
        "    )]\n",
        "    X_outras = X_test[np.random.choice(\n",
        "        idx_negativos, min(max_imgs, len(idx_negativos)), replace=False\n",
        "    )]\n",
        "\n",
        "    # Loop sobre os modelos\n",
        "    for i, (run_name, info) in enumerate(resultados.items(), start=1):\n",
        "        model = info[\"model\"]\n",
        "        print(f\"\\n=== Modelo {i} — {run_name} ===\")\n",
        "\n",
        "        dist_pos, dist_neg = [], []\n",
        "\n",
        "        # Calcula distâncias para pares da mesma classe\n",
        "        for a in X_classe:\n",
        "            for b in X_classe:\n",
        "                if not np.array_equal(a, b):\n",
        "                    d = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                    dist_pos.append(d)\n",
        "\n",
        "            # Calcula distâncias para pares de classes diferentes\n",
        "            for b in X_outras:\n",
        "                d = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                dist_neg.append(d)\n",
        "\n",
        "        # --- HISTOGRAMA ---\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.hist(dist_pos, bins=15, alpha=0.6, label='Mesma Classe', color='green')\n",
        "        plt.hist(dist_neg, bins=15, alpha=0.6, label='Classes Diferentes', color='red')\n",
        "        plt.xlabel(\"Distância (menor = mais similar)\")\n",
        "        plt.ylabel(\"Frequência\")\n",
        "        plt.title(f\"Distribuição de Distâncias — {classe_desejada}\\n{run_name}\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Distância média — Mesma classe: {np.mean(dist_pos):.3f}\")\n",
        "        print(f\"Distância média — Diferentes: {np.mean(dist_neg):.3f}\")\n",
        "\n",
        "        # --- EXEMPLOS VISUAIS ---\n",
        "        if mostrar_exemplos:\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
        "            fig.suptitle(f\"Exemplos de Comparação — {classe_desejada} ({run_name})\",\n",
        "                         fontsize=14)\n",
        "\n",
        "            # Pares da mesma classe\n",
        "            for j in range(3):\n",
        "                idx_a, idx_b = np.random.choice(range(len(X_classe)), 2, replace=False)\n",
        "                a, b = X_classe[idx_a], X_classe[idx_b]\n",
        "                dist = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                img_pair = np.hstack((np.squeeze(a), np.squeeze(b)))\n",
        "                axes[0, j].imshow(img_pair, cmap='gray')\n",
        "                axes[0, j].set_title(f\"Iguais — dist={dist:.3f}\")\n",
        "                axes[0, j].axis(\"off\")\n",
        "\n",
        "            # Pares de classes diferentes\n",
        "            for j in range(3):\n",
        "                a = X_classe[np.random.choice(len(X_classe))]\n",
        "                b = X_outras[np.random.choice(len(X_outras))]\n",
        "                dist = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                img_pair = np.hstack((np.squeeze(a), np.squeeze(b)))\n",
        "                axes[1, j].imshow(img_pair, cmap='gray')\n",
        "                axes[1, j].set_title(f\"Dif. — dist={dist:.3f}\")\n",
        "                axes[1, j].axis(\"off\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show(block=True)\n"
      ],
      "metadata": {
        "id": "FY6GoZIY_2Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loop Final Para Comparação**"
      ],
      "metadata": {
        "id": "sC2lS7fBADVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nome_modelo, modelo in modelos_numerados.items():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\" COMPARANDO MODELO: {nome_modelo}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Loop pelas classes disponíveis\n",
        "    for classe in classes:\n",
        "        print(f\"\\n Classe: {classe}\")\n",
        "\n",
        "        # Chamando a função de comparação visual\n",
        "        comparar_modelos_por_classe(\n",
        "            classe_desejada=classe,\n",
        "            X_test=X_test,\n",
        "            y_test=y_test,\n",
        "            classes=classes,\n",
        "            resultados={nome_modelo: {\"model\": modelo}},\n",
        "            max_imgs=3,\n",
        "            mostrar_exemplos=True\n",
        "        )"
      ],
      "metadata": {
        "id": "nxBp3vs3ACoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **O que está acontecendo**\n",
        "\n",
        "#### **1. Classes com poucas imagens**\n",
        "\n",
        "A função `comparar_modelos_por_classe` ignora qualquer classe que possua **menos de 2 imagens no conjunto de teste**.\n",
        "\n",
        "Isso **não é um erro**, apenas indica que o `X_test` tem poucas amostras para as classes:\n",
        "\n",
        "* **s1**\n",
        "* **s2**\n",
        "* **s6**\n",
        "* **s8**\n",
        "\n",
        "**Solução rápida:**\n",
        "Aumentar o número de imagens no conjunto de teste para essas classes ou duplicar temporariamente algumas amostras apenas para depuração.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Distâncias muito próximas entre pares iguais e diferentes**\n",
        "\n",
        "Alguns resultados observados:\n",
        "\n",
        "```\n",
        "Mesma classe:       0.000\n",
        "Classes diferentes: 0.003\n",
        "```\n",
        "\n",
        "Ou até inversões, como:\n",
        "\n",
        "```\n",
        "Mesma classe > Diferentes\n",
        "```\n",
        "\n",
        "Isso mostra que o modelo **não aprendeu uma métrica de distância útil**.\n",
        "Os embeddings estão **colapsando**, ficando praticamente todos iguais.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Por que isso está acontecendo?**\n",
        "\n",
        "As causas mais comuns para esse comportamento são:\n",
        "\n",
        "1. **Falta de normalização dos embeddings**\n",
        "\n",
        "   * Sem `K.l2_normalize`, o modelo pode contrair todos os embeddings para um único ponto.\n",
        "\n",
        "2. **Learning rate muito alto**\n",
        "\n",
        "   * Para *contrastive loss*, taxas altas tornam a convergência instável.\n",
        "\n",
        "3. **Pares negativos fáceis demais**\n",
        "\n",
        "   * Negativos aleatórios não obrigam a rede a aprender limites claros entre classes.\n",
        "\n",
        "---\n",
        "\n",
        "#### Interpretação rápida dos resultados por classe\n",
        "\n",
        "| Classe             | Problema observado                      | Diagnóstico provável                   |\n",
        "| ------------------ | --------------------------------------- | -------------------------------------- |\n",
        "| **s1, s2, s6, s8** | Poucas imagens                          | Dataset insuficiente no teste          |\n",
        "| **s3, s4, s5, s7** | Distâncias inconsistentes               | Embeddings colapsando                  |\n",
        "| **Geral**          | Distâncias muito próximas ou invertidas | Falta de aprendizado de contraste real |\n"
      ],
      "metadata": {
        "id": "tXYn5GYBAyFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **Novos Ajustes**"
      ],
      "metadata": {
        "id": "iQbbD-PvCkuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Rede Siamesa Otimizada com Contrastive Loss\n",
        "# ============================================================\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Função de perda Contrastiva\n",
        "# ------------------------------------------------------------\n",
        "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
        "    \"\"\"\n",
        "    y_true: 0 = mesma classe, 1 = diferentes\n",
        "    y_pred: distância euclidiana entre embeddings\n",
        "    \"\"\"\n",
        "    squared_pred = K.square(y_pred)\n",
        "    margin_term = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean((1 - y_true) * squared_pred + y_true * margin_term)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Distância Euclidiana entre embeddings\n",
        "# ------------------------------------------------------------\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Modelo base — extrator de embeddings com L2 normalization\n",
        "# ------------------------------------------------------------\n",
        "def criar_modelo_base(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    embedding = layers.Dense(64)(x)\n",
        "\n",
        "    # Normalização L2 — essencial para estabilidade da loss contrastiva\n",
        "    embedding = layers.Lambda(lambda t: K.l2_normalize(t, axis=1))(embedding)\n",
        "\n",
        "    return models.Model(inputs, embedding)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. Rede Siamesa completa\n",
        "# ------------------------------------------------------------\n",
        "def criar_rede_siamese(input_shape):\n",
        "    base_model = criar_modelo_base(input_shape)\n",
        "    input_a = layers.Input(shape=input_shape)\n",
        "    input_b = layers.Input(shape=input_shape)\n",
        "\n",
        "    embedding_a = base_model(input_a)\n",
        "    embedding_b = base_model(input_b)\n",
        "\n",
        "    distancia = layers.Lambda(euclidean_distance)([embedding_a, embedding_b])\n",
        "\n",
        "    siamese_model = models.Model(inputs=[input_a, input_b], outputs=distancia)\n",
        "\n",
        "    # Learning rate menor para estabilidade\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    siamese_model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
        "\n",
        "    return siamese_model\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. Gerar pares balanceados (positivos/negativos)\n",
        "# ------------------------------------------------------------\n",
        "def gerar_pares_balanceados(X, y, n_pairs_per_class=10):\n",
        "    pares_a, pares_b, labels = [], [], []\n",
        "    classes = np.unique(y)\n",
        "    idx_por_classe = {c: np.where(y == c)[0] for c in classes}\n",
        "\n",
        "    for c in classes:\n",
        "        idx_c = idx_por_classe[c]\n",
        "        if len(idx_c) == 0:\n",
        "            continue  # pula classe vazia\n",
        "\n",
        "        for _ in range(n_pairs_per_class):\n",
        "            # Pares positivos (mesma classe)\n",
        "            replace_flag = len(idx_c) < 2\n",
        "            i, j = np.random.choice(idx_c, 2, replace=replace_flag)\n",
        "            pares_a.append(X[i]); pares_b.append(X[j]); labels.append(0)\n",
        "\n",
        "            # Pares negativos (classes diferentes)\n",
        "            c_neg = np.random.choice(classes[classes != c])\n",
        "            idx_c_neg = idx_por_classe[c_neg]\n",
        "            i = np.random.choice(idx_c)\n",
        "            j = np.random.choice(idx_c_neg)\n",
        "            pares_a.append(X[i]); pares_b.append(X[j]); labels.append(1)\n",
        "\n",
        "    return np.array(pares_a), np.array(pares_b), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6. Converter distância → similaridade (para exibição)\n",
        "# ------------------------------------------------------------\n",
        "def prever_similaridade(model, img1, img2):\n",
        "    dist = model.predict([np.expand_dims(img1, 0), np.expand_dims(img2, 0)], verbose=0)\n",
        "    sim = np.exp(-dist)  # 0 = diferente, 1 = idêntico\n",
        "    return sim\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7. Função para comparação visual de modelos por classe\n",
        "# ------------------------------------------------------------\n",
        "def comparar_modelos_por_classe(classe_desejada, X_test, y_test, classes, resultados, max_imgs=5, mostrar_exemplos=True):\n",
        "    print(f\"\\nComparando modelos para a classe: {classe_desejada}\")\n",
        "\n",
        "    idx_classe = classes.index(classe_desejada)\n",
        "    idx_positivos = np.where(y_test == idx_classe)[0]\n",
        "    idx_negativos = np.where(y_test != idx_classe)[0]\n",
        "\n",
        "    if len(idx_positivos) < 2:\n",
        "        print(f\"Poucas imagens na classe {classe_desejada} para comparação.\")\n",
        "        return\n",
        "\n",
        "    X_classe = X_test[np.random.choice(idx_positivos, min(max_imgs, len(idx_positivos)), replace=False)]\n",
        "    X_outras = X_test[np.random.choice(idx_negativos, min(max_imgs, len(idx_negativos)), replace=False)]\n",
        "\n",
        "    for i, (run_name, info) in enumerate(resultados.items(), start=1):\n",
        "        model = info[\"model\"]\n",
        "        print(f\"\\n=== Modelo {i} — {run_name} ===\")\n",
        "\n",
        "        dist_pos, dist_neg = [], []\n",
        "\n",
        "        for a in X_classe:\n",
        "            for b in X_classe:\n",
        "                if not np.array_equal(a, b):\n",
        "                    d = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                    dist_pos.append(d)\n",
        "\n",
        "            for b in X_outras:\n",
        "                d = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                dist_neg.append(d)\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.hist(dist_pos, bins=15, alpha=0.6, label='Mesma Classe', color='green')\n",
        "        plt.hist(dist_neg, bins=15, alpha=0.6, label='Classes Diferentes', color='red')\n",
        "        plt.xlabel(\"Distância (menor = mais similar)\")\n",
        "        plt.ylabel(\"Frequência\")\n",
        "        plt.title(f\"Distribuição de Distâncias — {classe_desejada}\\n{run_name}\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Distância média — Mesma classe: {np.mean(dist_pos):.3f}\")\n",
        "        print(f\"Distância média — Diferentes: {np.mean(dist_neg):.3f}\")\n",
        "\n",
        "        if mostrar_exemplos:\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
        "            fig.suptitle(f\"Exemplos de Comparação — {classe_desejada} ({run_name})\", fontsize=14)\n",
        "            for j in range(3):\n",
        "                idx_a, idx_b = np.random.choice(range(len(X_classe)), 2, replace=False)\n",
        "                a, b = X_classe[idx_a], X_classe[idx_b]\n",
        "                dist = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                img_pair = np.hstack((np.squeeze(a), np.squeeze(b)))\n",
        "                axes[0, j].imshow(img_pair, cmap='gray')\n",
        "                axes[0, j].set_title(f\"Iguais — dist={dist:.3f}\")\n",
        "                axes[0, j].axis(\"off\")\n",
        "\n",
        "            for j in range(3):\n",
        "                a = X_classe[np.random.choice(len(X_classe))]\n",
        "                b = X_outras[np.random.choice(len(X_outras))]\n",
        "                dist = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                img_pair = np.hstack((np.squeeze(a), np.squeeze(b)))\n",
        "                axes[1, j].imshow(img_pair, cmap='gray')\n",
        "                axes[1, j].set_title(f\"Dif. — dist={dist:.3f}\")\n",
        "                axes[1, j].axis(\"off\")\n",
        "            plt.tight_layout()\n",
        "            plt.show(block=True)"
      ],
      "metadata": {
        "id": "KXhHdXroBKbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_train_a, pairs_train_b, y_train_pairs = gerar_pares_balanceados(X_train, y_train)\n",
        "pairs_val_a, pairs_val_b, y_val_pairs = gerar_pares_balanceados(X_val, y_val)\n",
        "pairs_test_a, pairs_test_b, y_test_pairs = gerar_pares_balanceados(X_test, y_test)\n",
        "input_shape = X_train.shape[1:]\n",
        "model = criar_rede_siamese(input_shape)\n",
        "history = model.fit(\n",
        "    [pairs_train_a, pairs_train_b], y_train_pairs,\n",
        "    validation_data=([pairs_val_a, pairs_val_b], y_val_pairs),\n",
        "    epochs=100, batch_size=256\n",
        ")\n",
        "modelos_numerados = {\"modelo_otimizado\": model}\n",
        "\n",
        "for nome_modelo, modelo in modelos_numerados.items():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\" COMPARANDO MODELO: {nome_modelo}\")\n",
        "    print(\"=\"*80)\n",
        "    for classe in classes:\n",
        "        comparar_modelos_por_classe(\n",
        "            classe_desejada=classe,\n",
        "            X_test=X_test,\n",
        "            y_test=y_test,\n",
        "            classes=classes,\n",
        "            resultados={nome_modelo: {\"model\": modelo}},\n",
        "            max_imgs=3,\n",
        "            mostrar_exemplos=True\n",
        "        )"
      ],
      "metadata": {
        "id": "hM6R5lbaCzVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Interpretação dos resultados e próximos passos**\n",
        "\n",
        "#### **Treinamento**\n",
        "\n",
        "A função de perda apresentou uma boa evolução:\n",
        "**de 0.55 → 0.07 ao longo de 100 épocas**, enquanto a `val_loss` permaneceu estável em torno de **0.35** durante todo o treinamento.\n",
        "\n",
        "Essa estabilidade indica que **não há overfitting**, nem explosões de gradiente — um ótimo sinal.\n",
        "Isso mostra que **o learning rate mais baixo** e a **normalização L2 dos embeddings** estão funcionando como esperado.\n",
        "\n",
        "\n",
        "#### *Métricas de Distância entre Embeddings*\n",
        "\n",
        "As novas distâncias médias ficaram assim:\n",
        "\n",
        "| Classe             | Mesma classe ↓ | Diferentes ↑ | Observação                         |\n",
        "| ------------------ | -------------- | ------------ | ---------------------------------- |\n",
        "| **s3**             | 0.262          | 0.183        | Diferença pequena → confusão       |\n",
        "| **s4**             | 0.098          | 0.187        | Já apresenta separação útil        |\n",
        "| **s5**             | 0.205          | 0.162        | Embeddings ainda muito próximos    |\n",
        "| **s7**             | 0.065          | 0.167        | Boa distinção → aprendizagem clara |\n",
        "| **s1, s2, s6, s8** | poucas imagens | —            | precisam de mais amostras          |\n",
        "\n",
        "\n",
        "#### **O que isso significa?**\n",
        "\n",
        "O modelo **já começou a aprender uma noção real de distância**, especialmente nas classes **s4** e **s7**, onde a separação entre pares iguais e diferentes aparece de forma consistente.\n",
        "\n",
        "Por outro lado, a diferença ainda é pequena em algumas classes. Idealmente, gostaríamos de algo como:\n",
        "\n",
        "* **Mesma classe:** ~0.1\n",
        "* **Classes diferentes:** **0.6 ou mais**\n",
        "\n",
        "Ou seja: o modelo está no caminho certo, mas ainda precisa reforçar melhor os contrastes entre classes — exatamente o que a *contrastive loss* foi feita para ensinar.\n",
        "\n"
      ],
      "metadata": {
        "id": "8u_av80uDAOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Novo Ajuste**"
      ],
      "metadata": {
        "id": "L2Br10GvEW-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# REDE SIAMESA FINAL OTIMIZADA — META-LEARNING / FEWSHOT\n",
        "# ============================================================\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Função de perda Contrastiva com margem ajustável\n",
        "# ------------------------------------------------------------\n",
        "def contrastive_loss(y_true, y_pred, margin=2.0):\n",
        "    \"\"\"\n",
        "    y_true: 0 = mesma classe, 1 = diferentes\n",
        "    y_pred: distância euclidiana entre embeddings\n",
        "    \"\"\"\n",
        "    squared_pred = K.square(y_pred)\n",
        "    margin_term = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean((1 - y_true) * squared_pred + y_true * margin_term)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Distância Euclidiana entre embeddings\n",
        "# ------------------------------------------------------------\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Modelo base com BatchNorm, Dropout e normalização L2\n",
        "# ------------------------------------------------------------\n",
        "def criar_modelo_base(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)  # 🔸 ajuda a generalizar\n",
        "\n",
        "    embedding = layers.Dense(64)(x)\n",
        "    embedding = layers.Lambda(lambda t: K.l2_normalize(t, axis=1))(embedding)\n",
        "\n",
        "    return models.Model(inputs, embedding)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Rede Siamesa completa\n",
        "# ------------------------------------------------------------\n",
        "def criar_rede_siamese(input_shape):\n",
        "    base_model = criar_modelo_base(input_shape)\n",
        "    input_a = layers.Input(shape=input_shape)\n",
        "    input_b = layers.Input(shape=input_shape)\n",
        "\n",
        "    embedding_a = base_model(input_a)\n",
        "    embedding_b = base_model(input_b)\n",
        "\n",
        "    distancia = layers.Lambda(euclidean_distance)([embedding_a, embedding_b])\n",
        "    siamese_model = models.Model(inputs=[input_a, input_b], outputs=distancia)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    siamese_model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
        "    return siamese_model\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Gerador de pares balanceado e robusto\n",
        "# ------------------------------------------------------------\n",
        "def gerar_pares_balanceados(X, y, n_pairs_per_class=50):\n",
        "    pares_a, pares_b, labels = [], [], []\n",
        "    classes = np.unique(y)\n",
        "    idx_por_classe = {c: np.where(y == c)[0] for c in classes}\n",
        "\n",
        "    for c in classes:\n",
        "        idx_c = idx_por_classe[c]\n",
        "        if len(idx_c) == 0:\n",
        "            continue\n",
        "\n",
        "        for _ in range(n_pairs_per_class):\n",
        "            # Pares positivos\n",
        "            replace_flag = len(idx_c) < 2\n",
        "            i, j = np.random.choice(idx_c, 2, replace=replace_flag)\n",
        "            pares_a.append(X[i]); pares_b.append(X[j]); labels.append(0)\n",
        "\n",
        "            # Pares negativos\n",
        "            c_neg = np.random.choice(classes[classes != c])\n",
        "            idx_c_neg = idx_por_classe[c_neg]\n",
        "            i = np.random.choice(idx_c)\n",
        "            j = np.random.choice(idx_c_neg)\n",
        "            pares_a.append(X[i]); pares_b.append(X[j]); labels.append(1)\n",
        "\n",
        "    return np.array(pares_a), np.array(pares_b), np.array(labels)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Converter distância → similaridade\n",
        "# ------------------------------------------------------------\n",
        "def prever_similaridade(model, img1, img2):\n",
        "    dist = model.predict([np.expand_dims(img1, 0), np.expand_dims(img2, 0)], verbose=0)\n",
        "    sim = np.exp(-dist)\n",
        "    return sim\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Função de comparação visual por classe\n",
        "# ------------------------------------------------------------\n",
        "def comparar_modelos_por_classe(classe_desejada, X_test, y_test, classes, resultados, max_imgs=5, mostrar_exemplos=True):\n",
        "    print(f\"\\nComparando modelos para a classe: {classe_desejada}\")\n",
        "\n",
        "    idx_classe = classes.index(classe_desejada)\n",
        "    idx_positivos = np.where(y_test == idx_classe)[0]\n",
        "    idx_negativos = np.where(y_test != idx_classe)[0]\n",
        "\n",
        "    if len(idx_positivos) < 2:\n",
        "        print(f\"Poucas imagens na classe {classe_desejada} para comparação.\")\n",
        "        return\n",
        "\n",
        "    X_classe = X_test[np.random.choice(idx_positivos, min(max_imgs, len(idx_positivos)), replace=False)]\n",
        "    X_outras = X_test[np.random.choice(idx_negativos, min(max_imgs, len(idx_negativos)), replace=False)]\n",
        "\n",
        "    for i, (run_name, info) in enumerate(resultados.items(), start=1):\n",
        "        model = info[\"model\"]\n",
        "        print(f\"\\n=== Modelo {i} — {run_name} ===\")\n",
        "\n",
        "        dist_pos, dist_neg = [], []\n",
        "\n",
        "        for a in X_classe:\n",
        "            for b in X_classe:\n",
        "                if not np.array_equal(a, b):\n",
        "                    d = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                    dist_pos.append(d)\n",
        "            for b in X_outras:\n",
        "                d = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                dist_neg.append(d)\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.hist(dist_pos, bins=15, alpha=0.6, label='Mesma Classe', color='green')\n",
        "        plt.hist(dist_neg, bins=15, alpha=0.6, label='Classes Diferentes', color='red')\n",
        "        plt.xlabel(\"Distância (menor = mais similar)\")\n",
        "        plt.ylabel(\"Frequência\")\n",
        "        plt.title(f\"Distribuição de Distâncias — {classe_desejada}\\n{run_name}\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Distância média — Mesma classe: {np.mean(dist_pos):.3f}\")\n",
        "        print(f\"Distância média — Diferentes: {np.mean(dist_neg):.3f}\")\n",
        "\n",
        "        if mostrar_exemplos:\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
        "            fig.suptitle(f\"Exemplos de Comparação — {classe_desejada} ({run_name})\", fontsize=14)\n",
        "            for j in range(3):\n",
        "                idx_a, idx_b = np.random.choice(range(len(X_classe)), 2, replace=False)\n",
        "                a, b = X_classe[idx_a], X_classe[idx_b]\n",
        "                dist = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                img_pair = np.hstack((np.squeeze(a), np.squeeze(b)))\n",
        "                axes[0, j].imshow(img_pair, cmap='gray')\n",
        "                axes[0, j].set_title(f\"Iguais — dist={dist:.3f}\")\n",
        "                axes[0, j].axis(\"off\")\n",
        "            for j in range(3):\n",
        "                a = X_classe[np.random.choice(len(X_classe))]\n",
        "                b = X_outras[np.random.choice(len(X_outras))]\n",
        "                dist = model.predict([a[None, ...], b[None, ...]], verbose=0)[0][0]\n",
        "                img_pair = np.hstack((np.squeeze(a), np.squeeze(b)))\n",
        "                axes[1, j].imshow(img_pair, cmap='gray')\n",
        "                axes[1, j].set_title(f\"Dif. — dist={dist:.3f}\")\n",
        "                axes[1, j].axis(\"off\")\n",
        "            plt.tight_layout()\n",
        "            plt.show(block=True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Treinamento e avaliação\n",
        "# ------------------------------------------------------------\n",
        "pairs_train_a, pairs_train_b, y_train_pairs = gerar_pares_balanceados(X_train, y_train, n_pairs_per_class=50)\n",
        "pairs_val_a, pairs_val_b, y_val_pairs = gerar_pares_balanceados(X_val, y_val, n_pairs_per_class=30)\n",
        "pairs_test_a, pairs_test_b, y_test_pairs = gerar_pares_balanceados(X_test, y_test, n_pairs_per_class=20)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "model = criar_rede_siamese(input_shape)\n",
        "\n",
        "history = model.fit(\n",
        "    [pairs_train_a, pairs_train_b], y_train_pairs,\n",
        "    validation_data=([pairs_val_a, pairs_val_b], y_val_pairs),\n",
        "    epochs=100, batch_size=256\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 9️ Visualização dos resultados\n",
        "# ------------------------------------------------------------\n",
        "modelos_numerados = {\"modelo_final_otimizado\": model}\n",
        "\n",
        "for nome_modelo, modelo in modelos_numerados.items():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\" COMPARANDO MODELO: {nome_modelo}\")\n",
        "    print(\"=\"*80)\n",
        "    for classe in classes:\n",
        "        comparar_modelos_por_classe(\n",
        "            classe_desejada=classe,\n",
        "            X_test=X_test,\n",
        "            y_test=y_test,\n",
        "            classes=classes,\n",
        "            resultados={nome_modelo: {\"model\": modelo}},\n",
        "            max_imgs=3,\n",
        "            mostrar_exemplos=True\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Visualização dos embeddings com t-SNE\n",
        "# ------------------------------------------------------------\n",
        "base_model = model.layers[2]  # extrai o submodelo de embeddings\n",
        "embeddings = base_model.predict(X_test)\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=10, random_state=42)\n",
        "emb_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=emb_2d[:,0], y=emb_2d[:,1], hue=y_test, palette='tab10', s=60)\n",
        "plt.title(\"Visualização dos embeddings (t-SNE)\")\n",
        "plt.xlabel(\"Dimensão 1\")\n",
        "plt.ylabel(\"Dimensão 2\")\n",
        "plt.legend(title=\"Classes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j3qCvOYUDSyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ANÁLISE DOS RESULTADOS — MODELO FINAL OTIMIZADO**\n",
        "\n",
        "O modelo foi treinado por 100 épocas com batch size = 256, normalização L2 e margem = 2.0.\n",
        "As curvas de loss indicaram convergência estável e contínua:\n",
        "\n",
        "    Loss inicial:     ~1.02\n",
        "    Val_loss inicial: ~1.54\n",
        "    Loss final:       ~0.38\n",
        "    Val_loss final:   ~0.73\n",
        "\n",
        " INTERPRETAÇÃO GERAL:\n",
        "- O modelo aprendeu uma métrica de similaridade real — não há colapso de embeddings.\n",
        "- As perdas diminuíram gradualmente, sem sinais de overfitting.\n",
        "- A normalização e o aumento de pares balanceados melhoraram a estabilidade do treino.\n",
        "\n",
        "#### **RESULTADOS POR CLASSE (distâncias médias)**\n",
        "\n",
        "| Classe             | Mesma Classe ↓ | Diferentes ↑ | Interpretação                                                    |\n",
        "| ------------------ | -------------- | ------------ | ---------------------------------------------------------------- |\n",
        "| **s3**             | 1.453          | 1.450        | Distâncias quase iguais → embeddings ainda pouco discriminativos |\n",
        "| **s4**             | 1.047          | 1.645        | Boa separação → métrica aprendida com sucesso                    |\n",
        "| **s5**             | 1.307          | 1.070        | Inversão parcial → confusão entre classes semelhantes            |\n",
        "| **s7**             | 1.782          | 1.231        | Boa separação, mas distâncias gerais muito altas                 |\n",
        "| **s1, s2, s6, s8** | —              | —            | Poucas imagens → não comparadas                                  |\n",
        "\n",
        "\n",
        " **CONCLUSÃO:**\n",
        "- O modelo estabilizou o aprendizado e diferencia melhor pares semelhantes e distintos.\n",
        "- Ainda há dispersão alta no espaço de embeddings (distâncias entre 1.0 e 1.7).\n",
        "- Classes com menos amostras precisam ser reforçadas no conjunto de teste.\n",
        "\n",
        " **PRÓXIMOS PASSOS:**\n",
        "\n",
        "1. Reduzir a margem da contrastive loss (ex: margin=1.0) → melhora compactação dos clusters.\n",
        "2. Normalizar a camada de distância (limitando valores entre 0 e 1).\n",
        "3. Treinar por mais 50–100 épocas, pois a loss ainda apresentava tendência de queda.\n",
        "4. Gerar mais pares por classe para diversificar amostras e reduzir viés.\n",
        "5. Visualizar os embeddings com t-SNE para confirmar a separação espacial entre classes.\n",
        "\n",
        " **Em resumo:**\n",
        "O modelo passou da fase de aprendizado básico (colapso de embeddings) para um estágio de refinamento da métrica de similaridade.\n",
        "A estrutura atual é funcional, e os ajustes seguintes devem focar em aperfeiçoar a separação entre classes no espaço vetorial."
      ],
      "metadata": {
        "id": "qzQqo3USEfzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Valiação de Similaridade com Múltiplas Imagens de Referência por Classe:**\n",
        "Para avaliar a robustez da métrica de similaridade no espaço de embeddings, calculou-se a similaridade média entre cada imagem do conjunto de teste e um conjunto de múltiplas imagens de referência por classe. O objetivo é verificar se o modelo consegue manter alta auto-similaridade intra-classe e baixa similaridade inter-classe, mesmo quando utiliza um conjunto diversificado de exemplos de suporte."
      ],
      "metadata": {
        "id": "KUWPu3nNFPY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Selecionar múltiplas imagens de referência por classe\n",
        "# ------------------------------------------------------------\n",
        "def selecionar_referencias_por_classe(X_ref, y_ref, classes, n_ref=5, random_state=42):\n",
        "    \"\"\"\n",
        "    Retorna um dicionário:\n",
        "        {nome_classe: array_indices_no_X_ref}\n",
        "    escolhendo até n_ref imagens por classe como \"suporte\" (referência).\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    idx_refs = {}\n",
        "\n",
        "    for idx_cls, nome_cls in enumerate(classes):\n",
        "        indices_da_classe = np.where(y_ref == idx_cls)[0]\n",
        "        if len(indices_da_classe) == 0:\n",
        "            continue\n",
        "\n",
        "        n_escolher = min(n_ref, len(indices_da_classe))\n",
        "        escolhidos = rng.choice(indices_da_classe, size=n_escolher, replace=False)\n",
        "        idx_refs[nome_cls] = escolhidos\n",
        "\n",
        "    return idx_refs\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Extrair embeddings das imagens de referência\n",
        "# ------------------------------------------------------------\n",
        "def construir_embeddings_referencia(base_model, X_ref, idx_refs):\n",
        "    \"\"\"\n",
        "    Usa o base_model (rede de embeddings) para projetar as imagens de referência\n",
        "    no espaço latente. Retorna:\n",
        "        {nome_classe: matriz [n_ref, dim_embedding]}\n",
        "    \"\"\"\n",
        "    emb_refs = {}\n",
        "    for nome_cls, indices in idx_refs.items():\n",
        "        emb = base_model.predict(X_ref[indices], verbose=0)\n",
        "        emb_refs[nome_cls] = emb\n",
        "    return emb_refs\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Calcular similaridade média de uma imagem para cada classe\n",
        "# ------------------------------------------------------------\n",
        "def similaridade_media_para_classes(emb_query, emb_refs_por_classe):\n",
        "    \"\"\"\n",
        "    Dado um embedding de consulta (emb_query) e um dicionário com os embeddings\n",
        "    de referência de cada classe, calcula a similaridade média da imagem de\n",
        "    consulta com cada classe, usando:\n",
        "        distância = norma L2\n",
        "        similaridade = exp(-distância)\n",
        "    Retorna um dicionário:\n",
        "        {nome_classe: similaridade_media}\n",
        "    \"\"\"\n",
        "    sims = {}\n",
        "    for nome_cls, emb_refs in emb_refs_por_classe.items():\n",
        "\n",
        "        dists = np.linalg.norm(emb_refs - emb_query, axis=1)\n",
        "        sim = np.exp(-dists)\n",
        "        sims[nome_cls] = sim.mean()\n",
        "    return sims\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Avaliar similaridade média em todo o conjunto de teste\n",
        "# ------------------------------------------------------------\n",
        "def avaliar_similaridade_multireferencia(base_model, emb_refs_por_classe,\n",
        "                                         X_test, y_test, classes,\n",
        "                                         max_por_classe=None):\n",
        "    \"\"\"\n",
        "    Percorre o conjunto de teste e calcula:\n",
        "        - similaridade média com a classe correta (same_class_sims)\n",
        "        - similaridade média com classes incorretas (diff_class_sims)\n",
        "    Também guarda estatísticas por classe em um dicionário.\n",
        "\n",
        "    max_por_classe: se não for None, limita a quantidade de imagens de teste\n",
        "    usadas por classe (só pra não ficar muito pesado).\n",
        "    \"\"\"\n",
        "    same_class_sims = []\n",
        "    diff_class_sims = []\n",
        "    por_classe = {nome: {\"same\": [], \"diff\": []} for nome in emb_refs_por_classe.keys()}\n",
        "\n",
        "    indices_para_usar = np.arange(len(X_test))\n",
        "    if max_por_classe is not None:\n",
        "        indices_para_usar = []\n",
        "        for idx_cls, nome_cls in enumerate(classes):\n",
        "            idxs = np.where(y_test == idx_cls)[0]\n",
        "            if len(idxs) == 0:\n",
        "                continue\n",
        "            n = min(max_por_classe, len(idxs))\n",
        "            chosen = np.random.choice(idxs, size=n, replace=False)\n",
        "            indices_para_usar.extend(chosen)\n",
        "        indices_para_usar = np.array(indices_para_usar)\n",
        "\n",
        "    for i in indices_para_usar:\n",
        "        img = X_test[i]\n",
        "        label_idx = y_test[i]\n",
        "        nome_true = classes[label_idx]\n",
        "\n",
        "\n",
        "        emb_query = base_model.predict(img[None, ...], verbose=0)[0]\n",
        "\n",
        "        sims = similaridade_media_para_classes(emb_query, emb_refs_por_classe)\n",
        "\n",
        "        for nome_cls, sim_media in sims.items():\n",
        "            if nome_cls == nome_true:\n",
        "                same_class_sims.append(sim_media)\n",
        "                por_classe[nome_cls][\"same\"].append(sim_media)\n",
        "            else:\n",
        "                diff_class_sims.append(sim_media)\n",
        "                por_classe[nome_cls][\"diff\"].append(sim_media)\n",
        "\n",
        "    same_class_sims = np.array(same_class_sims)\n",
        "    diff_class_sims = np.array(diff_class_sims)\n",
        "\n",
        "    print(f\"Similaridade média (global) — MESMA classe:    {same_class_sims.mean():.3f}\")\n",
        "    print(f\"Similaridade média (global) — CLASSES DIFER.: {diff_class_sims.mean():.3f}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(same_class_sims, bins=20, alpha=0.6, label='Mesma classe')\n",
        "    plt.hist(diff_class_sims, bins=20, alpha=0.6, label='Classes diferentes')\n",
        "    plt.xlabel(\"Similaridade média (exp(-distância))\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.title(\"Distribuição da similaridade média usando múltiplas imagens de referência\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Estatísticas por classe ---\")\n",
        "    for nome_cls, d in por_classe.items():\n",
        "        if len(d[\"same\"]) == 0:\n",
        "            continue\n",
        "        print(f\"\\nClasse: {nome_cls}\")\n",
        "        print(f\"  média (same) = {np.mean(d['same']):.3f}  |  desvio = {np.std(d['same']):.3f}\")\n",
        "        if len(d[\"diff\"]) > 0:\n",
        "            print(f\"  média (diff) = {np.mean(d['diff']):.3f}  |  desvio = {np.std(d['diff']):.3f}\")\n",
        "\n",
        "    return same_class_sims, diff_class_sims, por_classe\n"
      ],
      "metadata": {
        "id": "znLRtIbUE4Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Escolher, por exemplo, 5 imagens de referência por classe no conjunto de treino\n",
        "idx_refs = selecionar_referencias_por_classe(\n",
        "    X_ref=X_train,\n",
        "    y_ref=y_train,\n",
        "    classes=classes,\n",
        "    n_ref=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2) Construir embeddings das referências\n",
        "emb_refs_por_classe = construir_embeddings_referencia(\n",
        "    base_model=base_model,\n",
        "    X_ref=X_train,\n",
        "    idx_refs=idx_refs\n",
        ")\n",
        "\n",
        "# 3) Avaliar no conjunto de teste\n",
        "same_sims, diff_sims, stats_por_classe = avaliar_similaridade_multireferencia(\n",
        "    base_model=base_model,\n",
        "    emb_refs_por_classe=emb_refs_por_classe,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    classes=classes,\n",
        "    max_por_classe=50\n",
        ")"
      ],
      "metadata": {
        "id": "cL6eaMRHFi0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa, foi implementado um procedimento para avaliar a métrica aprendida pela rede no espaço de *embeddings*, utilizando múltiplas imagens de referência por classe. Inicialmente, são selecionados diversos exemplos de suporte para cada classe e, em seguida, seus *embeddings* são gerados pelo modelo base. Para cada imagem do conjunto de teste, obtém-se o *embedding* correspondente e calcula-se sua distância para todos os *embeddings* de referência de cada classe, convertendo essas distâncias em medidas de similaridade por meio da função.\n",
        "\n",
        "\n",
        "A similaridade média com cada classe é então utilizada para comparar, estatisticamente, a proximidade entre amostras da mesma classe e de classes distintas. Por fim, analisam-se as distribuições de similaridade — globais e por classe — permitindo avaliar o grau de separação entre as classes no espaço latente aprendido pelo modelo."
      ],
      "metadata": {
        "id": "1AwOK81jFpGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RESULTADOS OBTIDOS**\n",
        "\n",
        "- **Similaridade média** — mesma classe: 0.392\n",
        "\n",
        "- **Similaridade média** — classes diferentes: 0.329\n",
        "\n",
        "Esses valores indicam uma separação moderada entre as distribuições. Embora a diferença não seja grande, observa-se uma tendência de que amostras da mesma classe apresentem maior similaridade entre si, sugerindo que o modelo internalizou alguma estrutura interclasse. Ainda assim, a fronteira entre as classes permanece difusa.\n",
        "\n",
        "O histograma reforça esse comportamento:\n",
        "\n",
        "- as distribuições se sobrepõem significativamente;\n",
        "\n",
        "- porém há um deslocamento perceptível da curva de “mesma classe” para valores mais altos."
      ],
      "metadata": {
        "id": "QSy1hSNJF1yI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Análise por Classe**\n",
        "\n",
        "#### **Classes com melhor separação**\n",
        "\n",
        "**s1:** 0.591 (mesma) | 0.333 (diferentes)\n",
        "**s2:** 0.559 (mesma) | 0.352 (diferentes)\n",
        "\n",
        "Essas classes apresentam uma diferença nítida entre similaridade intra-classe e inter-classe, indicando que formaram **clusters bem definidos** no espaço de embeddings.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Classes com separação moderada**\n",
        "\n",
        "**s3:** 0.474 vs 0.373\n",
        "**s5:** 0.497 vs 0.338\n",
        "**s6:** 0.456 vs 0.390\n",
        "\n",
        "Aqui a separação existe, mas é **relativamente pequena**. As distribuições ainda se sobrepõem de maneira considerável, sugerindo que essas classes estão **parcialmente confundidas** com classes próximas.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Classes com comportamento invertido ou instável**\n",
        "\n",
        "**s7:** 0.182 vs 0.238\n",
        "**s8:** 0.159 vs 0.378\n",
        "\n",
        "Nessas classes, a similaridade média com outras classes é maior do que com elas mesmas — um comportamento **invertido**, indicando que o modelo está tendo dificuldade em posicioná-las corretamente no espaço latente.\n",
        "\n",
        "As causas mais prováveis incluem:\n",
        "\n",
        "* baixa variabilidade nos exemplos dessas classes;\n",
        "* embeddings pouco estruturados ou colapsados;\n",
        "* padrões visuais muito parecidos com os de outras classes.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "FYy1_qFFG51w"
      }
    }
  ]
}